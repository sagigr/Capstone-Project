## Capstone Project: Milestone Report

# Exploratory Data Analysis and Modeling

Sagi Greenstine

## About the Report and the Assignment

This is the Milestone Report of the [Capstone Project](https://www.coursera.org/learn/data-science-project) of Data Science Specialization introduced by Johns Hopkins University through Coursera.  
The main goal of the Capstone Project is creating a data product that can predict the next word that the user will type (predicting the next word based on the previous 1, 2, or 3 words, and building a model to handle cases where people will want to type a combination of words that does not appear in the corpora).  
The goal of this report is just to display that I've gotten used to working with the data and that I'm on track to create my prediction algorithm. The report explains my exploratory analysis and my goals for the eventual app and algorithm.

## Data Processing

### Loading and preprocessing the data

The [data set](https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip) is from a corpus called [HC Corpora](www.corpora.heliohost.org).

In this report I will use the English database, but the data set also includes three other databases in German, Russian and Finnish.  
In the English data set we have the three following files of the English Blogs, News and Twitter data:

- **en_US.blogs.txt** 
- **en_US.news.txt**
- **en_US.twitter.txt**

Let's see some basic details of these files, such as sizes of the files (Mbs):

```{r loaddata, cache=TRUE, warning=FALSE}
file.info("Coursera-Swiftkey/final/en_US/en_US.blogs.txt")$size / 1024^2
file.info("Coursera-Swiftkey/final/en_US/en_US.news.txt")$size / 1024^2
file.info("Coursera-Swiftkey/final/en_US/en_US.twitter.txt")$size / 1024^2

blogs <- readLines("Coursera-Swiftkey/final/en_US/en_US.blogs.txt")
news <- readLines("Coursera-Swiftkey/final/en_US/en_US.news.txt")
twitter <- readLines("Coursera-Swiftkey/final/en_US/en_US.twitter.txt")
```

Let's see some statistics about the data sets, such as:  
1. Lines - number of lines (number of non-missing strings in the vector);  
2. LinesNEmpty - number of lines with at least one non-WHITE_SPACE character;  
3. Chars - total number of Unicode code points detected;  
4. CharsNWhite - number of Unicode code points that are not WHITE_SPACEs;  

```{r statdataset,cache=TRUE, warning=FALSE}
library(stringi)
stri_stats_general(blogs)
stri_stats_general(news)
stri_stats_general(twitter)
```

## Results
